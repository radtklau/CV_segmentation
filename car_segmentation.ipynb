{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnvMYfHXlOLT"
      },
      "source": [
        "# Car & Human Segmentation | Computer Vision Final Project\n",
        "\n",
        "Segment cars and humans in a given picture.\n",
        "\n",
        "***Group***\n",
        "- Laurids Radtke\n",
        "- Giorgia Iacobellis\n",
        "- Thiago Costa\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics==8.0.196"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG9wtW9AQj2g",
        "outputId": "1378224a-9935-47eb-bf3d-586d6f84ac52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.0.196\n",
            "  Downloading ultralytics-8.0.196-py3-none-any.whl (631 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/631.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/631.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m624.6/631.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (0.13.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.196) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.0.196)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.0.196) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.196) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.196) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.196) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.196) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.196) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.196) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.196) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.196) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.0.196) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.0.196) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.0.196) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics==8.0.196) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQzuddaQlOLW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import cv2\n",
        "import plotly.express as px\n",
        "from plotly import subplots\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGIZjdytlOLU"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K88v2-RlOLV"
      },
      "source": [
        "In this project we are performing object segmentation on images. The goal is to detect humans and cars in various images. For the segmentation tasks we are using several pretrained models. For the baseline model we are using a simple ... model. For our high performance model we are using YOLO v?. After inference we evaluate the model predictions on the ... dataset. Afterwards we are comparing the performances of the two models to determine how much better the high performance model is compared to the baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzZrZu6hlOLV"
      },
      "source": [
        "### Strategy\n",
        "\n",
        "- download the dataset\n",
        "- preprocessing of the dataset (more detailed)\n",
        "- baseline model for comparison\n",
        "- high performance model\n",
        "- evaluation each model\n",
        "- comparison of models to define the best one\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ],
      "metadata": {
        "id": "6986RuZf0EvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def yolo_evaluation(path):\n",
        "  model = YOLO(path)\n",
        "  metrics = model.val()\n",
        "  print(metrics)\n",
        "  return metrics.results_dict\n",
        "\n",
        "def results_table(names, data):\n",
        "  # Add an additional column for dictionary names\n",
        "  columns = ['Trainings'] + list(data[0].keys())\n",
        "\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "\n",
        "  # Populate the DataFrame with dictionary values\n",
        "  for i, d in enumerate(data):\n",
        "      df.loc[i] = [names[i]] + list(d.values())\n",
        "\n",
        "  # Display the DataFrame using tabulate for a prettier format\n",
        "  table = tabulate(df, headers='keys', tablefmt='pretty', showindex=False)\n",
        "\n",
        "  print(table)"
      ],
      "metadata": {
        "id": "HqELUQvm0Hwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2netsnslOLW"
      },
      "source": [
        "### Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def crop_images(path=\"/content/data/\"):\n",
        "  for file in os.listdir(path):\n",
        "    if file.endswith(\".jpg\"):\n",
        "      print(f'saving {file}')\n",
        "      cropcrop(f'{path}{file}', file)\n",
        "\n",
        "def cropcrop(path, filename):\n",
        "  img = cv2.imread(path)  # Use cv2.imread to read the image with OpenCV\n",
        "  img1 = img[:, :256]  # Crop the left half of the image\n",
        "  img2 = img[:, 256:512]  # Crop the right half of the image\n",
        "\n",
        "  cv2.imwrite(f'./data/images/{filename}', img1)\n",
        "  cv2.imwrite(f'./data/labels/{filename}', img2)"
      ],
      "metadata": {
        "id": "qJWoIriaMsaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_images()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4sQlPwUQNN2",
        "outputId": "b18c1427-5cd3-4d75-a50c-6055c54621c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving 5.jpg\n",
            "saving 2.jpg\n",
            "saving 3.jpg\n",
            "saving 11.jpg\n",
            "saving 9.jpg\n",
            "saving 6.jpg\n",
            "saving 7.jpg\n",
            "saving 8.jpg\n",
            "saving 4.jpg\n",
            "saving 10.jpg\n",
            "saving 1.jpg\n",
            "saving 12.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnmO-Nb-lOLY"
      },
      "source": [
        "### Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62AbFmE6lOLY"
      },
      "outputs": [],
      "source": [
        "# baseline = yolo_evaluation('yolov8n-seg.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def path_extraction(path=\"/content/data/images/\"):\n",
        "  image_paths = []\n",
        "  for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "      if file.lower().endswith('.jpg'):\n",
        "        image_paths.append(os.path.join(root, file))\n",
        "  return image_paths\n",
        "\n",
        "image_paths = path_extraction()"
      ],
      "metadata": {
        "id": "cXo_vFqJAZ-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, images, model_name, pred_args):\n",
        "  \"\"\"\n",
        "  Take model and images and predict segmentation on images.\n",
        "  Return predicted segmentation as array of masks.\n",
        "  \"\"\"\n",
        "  if model_name == \"YOLO\":\n",
        "    results = model.predict(images)\n",
        "    mask_list = []\n",
        "    for result in results:\n",
        "      mask = result.masks.numpy()\n",
        "      mask_list.append(mask)\n",
        "\n",
        "    for r in results:\n",
        "        im_array = r.plot()  # plot a BGR numpy array of predictions\n",
        "        im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "        im.show()  # show image\n",
        "        im.save('results.jpg')  # save image\n",
        "\n",
        "  else:\n",
        "    mask_list = []\n",
        "    for image in images:\n",
        "      mask = model.predict(image, args=pred_args)\n",
        "      masks.append(mask)\n",
        "    masks = np.array(masks)\n",
        "\n",
        "  return mask_list\n",
        "\n",
        "model = YOLO(\"yolov8n-seg.pt\")\n",
        "model_name = \"YOLO\"\n",
        "masks = prediction(model, image_paths, \"YOLO\",[])\n"
      ],
      "metadata": {
        "id": "nl6loEcY5QDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507fb092-b4dc-4386-e944-88039139a546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "0: 640x640 3 cars, 1 bus, 1: 640x640 6 cars, 1 potted plant, 2: 640x640 2 persons, 7 cars, 3: 640x640 2 cars, 4: 640x640 1 bicycle, 2 cars, 4 buss, 2 trucks, 1 clock, 5: 640x640 2 cars, 1 bus, 6: 640x640 5 cars, 1 bus, 7: 640x640 2 cars, 3 buss, 1 truck, 1 traffic light, 8: 640x640 4 cars, 1 bus, 1 traffic light, 9: 640x640 1 car, 2 buss, 10: 640x640 1 car, 1 bus, 11: 640x640 1 person, 1 car, 5582.2ms\n",
            "Speed: 6.9ms preprocess, 465.2ms inference, 21.3ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in masks:\n",
        "  print(x.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vPVmQEETIRm",
        "outputId": "eb8cc121-9993-4b66-fa1c-f974b871dfd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 640, 640)\n",
            "(7, 640, 640)\n",
            "(9, 640, 640)\n",
            "(2, 640, 640)\n",
            "(10, 640, 640)\n",
            "(3, 640, 640)\n",
            "(6, 640, 640)\n",
            "(7, 640, 640)\n",
            "(6, 640, 640)\n",
            "(3, 640, 640)\n",
            "(2, 640, 640)\n",
            "(2, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(masks, labels):\n",
        "  \"\"\"\n",
        "  Take predicted masks and ground truth masks and calculate different evaluation scores like overlap.\n",
        "  Return the scores in a list.\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for pred_masks, gt_masks in zip(masks, labels):\n",
        "    sc1 = compute_overlap(pred_masks, gt_masks)\n",
        "    sc2 = compute_MAP(pred_masks, gt_masks, thresh=0.5)\n",
        "    sc3 = compute_MAP(pred_masks, gt_masks, thresh=0.75)\n",
        "    score = (sc1, sc2, sc3)\n",
        "    scores.append(score)\n",
        "  return np.array(scores)"
      ],
      "metadata": {
        "id": "s_WwQAmu5fsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_overlap(pred_masks, gt_masks):\n",
        "  return 1"
      ],
      "metadata": {
        "id": "KTsbiyg0D20B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_MAP(pred_masks, gt_masks, thresh=0):\n",
        "  return 1"
      ],
      "metadata": {
        "id": "-tfvwSbfEgLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def table(model_scores): # {model1: [(1,2,3), (3,2,1)], model2: [(1,2,2), (3,2,5)]}\n",
        "  print(model_scores)\n",
        "  \"\"\"\n",
        "  Take a list of scores from different models and create a table for an overview over the performance.\n",
        "  Return the table or plot it.\n",
        "  \"\"\"\n",
        "  # Add an additional column for dictionary names\n",
        "  columns = ['Trainings'] + list(data[0].keys())\n",
        "\n",
        "  df = pd.DataFrame(columns=columns)\n",
        "\n",
        "  # Populate the DataFrame with dictionary values\n",
        "  for i, d in enumerate(data):\n",
        "      df.loc[i] = [names[i]] + list(d.values())\n",
        "\n",
        "  # Display the DataFrame using tabulate for a prettier format\n",
        "  table = tabulate(df, headers='keys', tablefmt='pretty', showindex=False)\n",
        "\n",
        "  print(table)\n",
        "  return table"
      ],
      "metadata": {
        "id": "nDFUI0fi5urb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QyGNs0giPvUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8_gzcSflOLY"
      },
      "source": [
        "...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psa5DeC8lOLY"
      },
      "source": [
        "### High Performance Model - Yolo V8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_img_yolo(path):\n",
        "  model = YOLO(\"yolov8m-seg.pt\")\n",
        "  img = cv2.imread(path)\n",
        "\n",
        "  yolo_classes = list(model.names.values())\n",
        "  classes_ids = [yolo_classes.index(clas) for clas in yolo_classes]\n",
        "\n",
        "  conf = 0.5\n",
        "\n",
        "  results = model.predict(img, conf=conf)\n",
        "\n",
        "  colors = [random.choices(range(256), k=3) for _ in classes_ids]\n",
        "\n",
        "  colors[0] = (0,  0, 142) # person\n",
        "  colors[2] = (220, 20, 60) # car\n",
        "\n",
        "  for result in results:\n",
        "      for mask, box in zip(result.masks.xy, result.boxes):\n",
        "          points = np.int32([mask])\n",
        "          color_number = classes_ids.index(int(box.cls[0]))\n",
        "          cv2.fillPoly(img, points, colors[color_number])\n",
        "\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "lGobl3K0ncTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHuTBRp-lOLZ"
      },
      "source": [
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QAmDaIglOLZ"
      },
      "source": [
        "### Validation & Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhrjTwA_lOLZ"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL1jUeMvlOLZ"
      },
      "source": [
        "...."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}